{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import dirname, join as pjoin\n",
    "import scipy.io as sio\n",
    "import h5py\n",
    "import hdf5storage\n",
    "import random\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.models import load_model\n",
    "from PIL import Image\n",
    "from matplotlib.image import imread\n",
    "import os\n",
    "from tensorflow.keras import applications\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (27455, 785)\n",
      "Test set: (7172, 785)\n",
      "(27455, 24)\n",
      "(7172, 24)\n"
     ]
    }
   ],
   "source": [
    "DATASET_ROOT = '/home/maxim/Desktop/ml_dataset/sign-language-mnist/'\n",
    "\n",
    "train_data = pd.read_csv(DATASET_ROOT + '/sign_mnist_train.csv')\n",
    "test_data = pd.read_csv(DATASET_ROOT + '/sign_mnist_test.csv')\n",
    "print('Train set: ' + str(train_data.shape))\n",
    "print('Test set: ' + str(test_data.shape))\n",
    "\n",
    "binarizer = LabelBinarizer()\n",
    "\n",
    "train_labels = train_data['label'].values\n",
    "train_labels = binarizer.fit_transform(train_labels)\n",
    "train_data.drop('label', axis = 1, inplace = True)\n",
    "\n",
    "test_labels = test_data['label'].values\n",
    "test_labels = binarizer.fit_transform(test_labels)\n",
    "test_data.drop('label', axis = 1, inplace = True)\n",
    "\n",
    "print(str(train_labels.shape))\n",
    "print(str(test_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27455, 784)\n",
      "(7172, 784)\n"
     ]
    }
   ],
   "source": [
    "VALIDATION_SET_RATE = 0.05\n",
    "\n",
    "IMAGE_WIDTH = 28\n",
    "IMAGE_HEIGHT = 28\n",
    "IMAGE_CHANNELS = 1\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS_COUNT = 5\n",
    "\n",
    "train_values = train_data.values\n",
    "test_values = test_data.values\n",
    "print(train_values.shape)\n",
    "print(test_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26082, 28, 28, 1)\n",
      "(1373, 28, 28, 1)\n",
      "(7172, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# SPLIT ON SETS\n",
    "x_train = np.asarray(train_values).reshape(train_values.shape[0], IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)\n",
    "x_test = np.asarray(test_values).reshape(test_values.shape[0], IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)\n",
    "\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(\n",
    "    x_train,\n",
    "    train_labels,\n",
    "    test_size = VALIDATION_SET_RATE, \n",
    "    stratify = train_labels\n",
    ")\n",
    "y_test = test_labels\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_validation.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26082, 32, 32, 3)\n",
      "(7172, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# PUT IN IMAGE DATA GENERATOR\n",
    "\n",
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "test_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "validation_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "au_validation_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "au_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    width_shift_range=0.2, \n",
    "    height_shift_range=0.2, \n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "data_loader = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "modified_image_shape = (32, 32, 3)\n",
    "\n",
    "x_train_vgg = np.pad(\n",
    "    x_train,\n",
    "    ((0,0),(2,2),(2,2),(0,0)),\n",
    "    'edge'\n",
    ")\n",
    "x_train_vgg = np.repeat(x_train_vgg, 3, axis=3)\n",
    "train_flow_vgg = data_loader.flow(\n",
    "    x_train_vgg,\n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "x_test_vgg = np.pad(\n",
    "    x_test,\n",
    "    ((0,0),(2,2),(2,2),(0,0)),\n",
    "    'edge'\n",
    ")\n",
    "x_test_vgg = np.repeat(x_test_vgg, 3, axis=3)\n",
    "test_flow_vgg = data_loader.flow(\n",
    "    x_test_vgg,\n",
    "    y_test,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "print(x_train_vgg.shape)\n",
    "print(x_test_vgg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DESCRIBE FLOWS\n",
    "\n",
    "train_flow = image_generator.flow(x_train, y_train)\n",
    "validation_flow = validation_image_generator.flow(x_validation, y_validation)\n",
    "test_flow = test_image_generator.flow(x_test, y_test)\n",
    "au_train_flow = au_image_generator.flow(x_train, y_train)\n",
    "au_validation_flow = au_validation_image_generator.flow(x_validation, y_validation)\n",
    "# vgg_flow = vgg_image_generator.flow(x_train, y_train)\n",
    "# resnet_flow = resnet_image_generator.flow(x_train, y_train)\n",
    "\n",
    "STEPS_PER_EPOCH_TRAIN = 800\n",
    "AU_STEPS_PER_EPOCH_TRAIN = 600\n",
    "VGG_STEPS_PER_EPOCH_TRAIN = 800\n",
    "RESNET_STEPS_PER_EPOCH_TRAIN = 800\n",
    "STEPS_PER_EPOCH_VALIDATION = 100\n",
    "AU_STEPS_PER_EPOCH_VALIDATION = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 39,937\n",
      "Trainable params: 39,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# DEFINE THE MODEL\n",
    "\n",
    "input_layer = layers.Input(shape=((IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)))\n",
    "conv_1 = layers.Conv2D(16, kernel_size=(3, 3), padding='valid')\n",
    "conv_2 = layers.Conv2D(32, kernel_size=(3, 3), padding='valid')\n",
    "conv_3 = layers.Conv2D(64, kernel_size=(3, 3), padding='valid')\n",
    "mp_1 = layers.MaxPooling2D(strides=(2, 2))\n",
    "mp_2 = layers.MaxPooling2D(strides=(2, 2))\n",
    "mp_3 = layers.MaxPooling2D(strides=(2, 2))\n",
    "\n",
    "fc_1 = layers.Dense(128, activation='relu')\n",
    "fc_2 = layers.Dense(64, activation='relu')\n",
    "\n",
    "out_layer = layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "model = keras.Sequential([\n",
    "        input_layer,\n",
    "        conv_1,\n",
    "        mp_1,\n",
    "        conv_2,\n",
    "        mp_2,\n",
    "        conv_3,\n",
    "        mp_3,\n",
    "        layers.Flatten(),\n",
    "        fc_1,\n",
    "        fc_2,\n",
    "        out_layer\n",
    "    ])\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "if os.path.exists('three_conv.h5'):\n",
    "    model = load_model('three_conv.h5')\n",
    "else:\n",
    "    history = model.fit_generator(\n",
    "        train_flow,\n",
    "        validation_data=validation_flow,\n",
    "        steps_per_epoch=STEPS_PER_EPOCH_TRAIN,\n",
    "        validation_steps=STEPS_PER_EPOCH_VALIDATION,\n",
    "        epochs=EPOCHS_COUNT,\n",
    "        verbose=1\n",
    "    )\n",
    "    model.save('three_conv.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.1835 - accuracy: 0.9583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1835441952281528, 0.9583319]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 39,937\n",
      "Trainable params: 39,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "au_input_layer = layers.Input(shape=((IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)))\n",
    "au_conv_1 = layers.Conv2D(16, kernel_size=(3, 3), padding='valid')\n",
    "au_conv_2 = layers.Conv2D(32, kernel_size=(3, 3), padding='valid')\n",
    "au_conv_3 = layers.Conv2D(64, kernel_size=(3, 3), padding='valid')\n",
    "au_mp_1 = layers.MaxPooling2D(strides=(2, 2))\n",
    "au_mp_2 = layers.MaxPooling2D(strides=(2, 2))\n",
    "au_mp_3 = layers.MaxPooling2D(strides=(2, 2))\n",
    "\n",
    "au_fc_1 = layers.Dense(128, activation='relu')\n",
    "au_fc_2 = layers.Dense(64, activation='relu')\n",
    "\n",
    "au_out_layer = layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "au_model = keras.Sequential([\n",
    "        au_input_layer,\n",
    "        au_conv_1,\n",
    "        au_mp_1,\n",
    "        au_conv_2,\n",
    "        au_mp_2,\n",
    "        au_conv_3,\n",
    "        au_mp_3,\n",
    "        layers.Flatten(),\n",
    "        au_fc_1,\n",
    "        au_fc_2,\n",
    "        au_out_layer\n",
    "    ])\n",
    "au_model.summary()\n",
    "\n",
    "au_model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('three_conv_au.h5'):\n",
    "    au_model = load_model('three_conv_au.h5')\n",
    "else:\n",
    "    au_history = au_model.fit_generator(\n",
    "        au_train_flow,\n",
    "        validation_data=au_validation_flow,\n",
    "        steps_per_epoch=AU_STEPS_PER_EPOCH_TRAIN,\n",
    "        validation_steps=AU_STEPS_PER_EPOCH_VALIDATION,\n",
    "        epochs=EPOCHS_COUNT,\n",
    "        verbose=1\n",
    "    )\n",
    "    au_model.save('three_conv_au.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.1732 - accuracy: 0.9583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17324417677190568, 0.9583319]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On augumented 3-conv\n",
    "au_model.evaluate(test_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 14,780,481\n",
      "Trainable params: 65,793\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# VGG-16\n",
    "keras.backend.clear_session()\n",
    "    \n",
    "# Load model and mark pretrained layers as not trainable\n",
    "vgg16 = applications.VGG16(include_top=False, input_shape=(32, 32, 3))\n",
    "for layer in vgg16.layers:\n",
    "    layer.trainable = False\n",
    "        \n",
    "# Forward pretrained model output into new layers\n",
    "x = layers.Flatten()(vgg16.layers[-1].output)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "output = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "# Compile model\n",
    "vgg16 = keras.Model(inputs=vgg16.inputs, outputs=output)\n",
    "vgg16.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('vgg16.h5'):\n",
    "    vgg16 = load_model('vgg16.h5')\n",
    "else:\n",
    "    vgg_history = vgg16.fit_generator(\n",
    "        train_flow_vgg,\n",
    "        steps_per_epoch=VGG_STEPS_PER_EPOCH_TRAIN,\n",
    "        epochs=1,\n",
    "        verbose=1\n",
    "    )\n",
    "    vgg16.save('vgg16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "225/225 [==============================] - 20s 90ms/step - loss: 0.1733 - accuracy: 0.9583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17326274580425685, 0.9583319]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16.evaluate(test_flow_vgg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
