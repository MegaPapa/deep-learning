{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/maxim/.keras/datasets/notMNIST_small\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import numpy as np\n",
    "\n",
    "data_root_orig = tf.keras.utils.get_file(origin='https://commondatastorage.googleapis.com/books1000/notMNIST_small.tar.gz',\n",
    "                                         fname='notMNIST_small', untar=True)\n",
    "data_root = pathlib.Path(data_root_orig)\n",
    "print(data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/maxim/.keras/datasets/notMNIST_small/F\n",
      "/home/maxim/.keras/datasets/notMNIST_small/B\n",
      "/home/maxim/.keras/datasets/notMNIST_small/H\n",
      "/home/maxim/.keras/datasets/notMNIST_small/G\n",
      "/home/maxim/.keras/datasets/notMNIST_small/D\n",
      "/home/maxim/.keras/datasets/notMNIST_small/I\n",
      "/home/maxim/.keras/datasets/notMNIST_small/C\n",
      "/home/maxim/.keras/datasets/notMNIST_small/A\n",
      "/home/maxim/.keras/datasets/notMNIST_small/J\n",
      "/home/maxim/.keras/datasets/notMNIST_small/E\n"
     ]
    }
   ],
   "source": [
    "for letter_dir in data_root.iterdir():\n",
    "  print(letter_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18724"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "all_image_paths = list(data_root.glob('*/*'))\n",
    "all_image_paths = [str(path) for path in all_image_paths]\n",
    "random.shuffle(all_image_paths)\n",
    "\n",
    "image_count = len(all_image_paths)\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABpElEQVR4nHXSP2iUQRAF8Le7h5q7iKBBsdDGIgheoRBBULCwiaYwyG2TQpQ06fxT2IidNlaCipWFhTYKEhsRTReIhYQoBiwURIgpQgKJp7e7s/Msvqj33X1O+ytmePMw/nQPrDOonBaXbuz6H3tGfr+yvZo9gyg/T26FrfWxZ2IW5QfvYF0Fkjko50bRy56JzOuUqHxzAsbZMirXmw86lEg+P1Jiz6RsN3DoiTAlxkfDXVzgIAxGXpBR2L677y8XWIdzBidnqEG4dmsIxpkuNHAWOPOWGoTL14pU/iHgLJx/T5XMr1PbUEaYmsXAhXfMolyc3FFGwNWAS6TGzIWDZbQOODXPLMpvF233QTDOYvhZZhS2b+6E3dz5ow4DazF0+ydjoDw+ULzQM5EbDTiLLVNLlKCcPQ4UKXiGzLUGDEbnqR3hlwmHP/m1GDlzDGhOU4Nw9Xqj628tfpow2H3nF1OkPNy/GVwxp+8Non55mRKUr4/2/BOwZz8yB+XiuT7C4ZdkSFy5Wu/v0FibMbFzf29VOe35Fcp0s7q3FiOvWkDvMgDAb885DDxUX9B/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/maxim/.keras/datasets/notMNIST_small/D/Q2xlb3BhdHJhLm90Zg==.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAByElEQVR4nG2TT0iVQRTFf3dmnn5CBUL0pHhEZRpKEtGiFrUOatkfWmer2gYt2kRQm1oJ7QIj3AhBQSSE0MJNEESuSsyMtBeFWllift+bOS3eexn6zmZgfpx7zx3u2KeKjP+U1la/z754OOeTsOGBzooH2dePS8tx2779AWQ/bt0BAdmsogpdwAO+byhXLUbdx8BgRlGFztAWgsNxKldKuS7jMWvAswTAfBs3VFPUuzac1EhSPxVrjBZejt4DODZKfPsDJLIW0NGzFeQW5jdD77hEtIKnVQ/NtOdo9z4446piUehtV93YHCUADDxSVNJYGVe/AIye/s72cv/xoyXS/OTw42SJprOhpF+jgwcDBA8YMLM3ueTuTezIyt293X5xemp8bNGx7mz2zA7f/amo6rXmlHV4nix4h7FrXHnUqz0t0vpAx0sVuaa7NpUFSpxQUq6RVtAovVaU8iOb3xb5YpZEKp1sATFyQOxuBSMVDFhtAYMOHcNhTK7DxoK6ELnpoiU398T9owIfvKmWPTidXE1cXwA66qt5EQ9YeXBKeUwqruBspHd7xQGsfakurmQ7+7YA/H52+42PttS54Tssr3x+P/H8Az7yFwklAtFCtwCeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/maxim/.keras/datasets/notMNIST_small/B/Q2xlcmZhY2UtRGVtaUJvbGQub3Rm.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABfUlEQVR4nG2RT0tUYRTGf+e81zGdC2IMCLWQhkYUFHOYheB3sFX4AQJ3rltJ+1q7EPoARQSJC9F1uqiFoozaH0qwFpFoSOK/e9/TYua9jbf7LN/f+zzn4RwBUVJw9+vVW0Jb0tPH+zfgFMoPFz6Ztw6lazO3EWBy9lGcftgeHX92EhmA6eXKNzEoTa//3ngy1Tv04vwLHdJIYGp1roLSv2f2llJXkGa/pJu6v7SnOG4oQtR8QlWMHSQPLQWjTuniALsJQ3YDOTzAF0Dx3TX4fuyKnMJwBZqd79KaCagfiZNo619Z85ZBGMZ4R5LN7LpzdtSGCWO4dPEitIvjn8uvEGvl9362NNu7t1/Pa0gWO3DP69J83E6VjyctWwRo+sAlurETJWGkMx8KCRMoTTS09WlYHxij6Ok217kdtPrEm2b7/wMUhLs1Yyt/kgAHy1dsokUQJhD2ip1Gg9Lp1/y9gnbNmuVCp1KtwI+z/DEBcEzbn9eNAiPgePxyqBj9BfnnkZ5prbVsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/maxim/.keras/datasets/notMNIST_small/F/QXVndXN0YVN0ZC1SZWd1bGFyLm90Zg==.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABhElEQVR4nF3Sv2sUQRQH8O+b3b09T5JcRBSvSIRIEA6JJFUCUUEL0cLCgI3/gVjY2Qj+FynTBLsUF7BOkUpRDEjgsuePQvAkZ+6X2bvc7c57Fpdk39y3esyHmXlvGMLzR/NxasXz/CDI5cIwDAMTH3550QB8vJ96GhDcTMaJjKqbb1psR2FmFhGJN4oGAEBm5uuJuKmsAQAMhDvvauKcKjs7NEKgv/XTuXT4uXokZziMvv3VOPhwSDhDULXq7NxrSIZSq2lMvneRIaLI6acz1Fiva+TWQCP326zUNxoxaCr0rl5wsPFpoPCKi9FmnKG5nHewfZBkGNwokkZO1Ovm75dEY1j0Mszdnr3o4CWjRjHlMimcuO4rxPKyZEil1VDj0t3Z4Bzl2r28Rlp4NXFez70d+yf8a7FAAEAGr/fHUHrbd0AAUeHJ7rgJy/oKAEw/+DHk0QqztWmaptYy28otQvnZy0k95GnkX/TRp8cPkzjwPWvTNO33er3j427zqNn4/ad98h/6Dd+9M3znrwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/maxim/.keras/datasets/notMNIST_small/I/RlogQkFTSUMgMTIudHRm.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABjElEQVR4nH2SMUgcQRSGv3mz5xGDcjE2EWIRPAlYWOUiWoUgWKWx0NJOUgiCiBYqXJUihBBISiEEUohYpUmVNDYSkjZgIIQLSBDBw3iHe7uzz2Jvb/duQ14zw/vm/9/PzED/zq9W83AGoV2GuaNG8Lt6A0qfLzcePTmIFrAxE1b03dzszt9PN3mjE4jw3L8Ta4WybmOFsdZLrt7SZwuM+k9jqWX1YpiCLfLi3Ct+I3LO1GqTmHhi+eRMAgw/S4Ift6L+NFBcLpuxtzSFmoPgZfbGACbj0YHOoQooocvB5tJUnwKmdf9rD1S27ibjtZYE6MCP3UG7bQtpDg16ZwbkqwPLg4lUL350Q4neP6jH+7D0pSJRt3Jgb3E4BLyz3emcrfjUQ8DDNzmI+c/1QXJ96RPIP94qA9sHTSowKUyMm0krbK9F5HQSsV40cOt77KEc3x6MPCtU6lTdOGJZ1nvJ1xwJNrHChL7G+9BYn3n8SteTT21ZCPdnK2uNoyEoVs/VHc9nYzw89N2fZyWuAXnQfbxOtANRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/maxim/.keras/datasets/notMNIST_small/H/QUdCdWNoUm91bmRlZEJRLUJvbGRPdXRsaW5lLm90Zg==.png\n"
     ]
    }
   ],
   "source": [
    "all_image_paths[:10]\n",
    "\n",
    "import IPython.display as display\n",
    "\n",
    "for n in range(5):\n",
    "  image_path = random.choice(all_image_paths)\n",
    "  display.display(display.Image(image_path))\n",
    "  print(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0,\n",
       " 'B': 1,\n",
       " 'C': 2,\n",
       " 'D': 3,\n",
       " 'E': 4,\n",
       " 'F': 5,\n",
       " 'G': 6,\n",
       " 'H': 7,\n",
       " 'I': 8,\n",
       " 'J': 9}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_index = dict((name, index) for index, name in enumerate(label_names))\n",
    "label_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 labels indices:  [4, 8, 7, 9, 3, 6, 2, 9, 5, 0]\n",
      "First 10 paths:  ['/home/maxim/.keras/datasets/notMNIST_small/E/QmVhY2ggVGhpbiBCb2xkLnR0Zg==.png', '/home/maxim/.keras/datasets/notMNIST_small/I/Qm9va21hblN0ZC1Cb2xkSXRhbGljLm90Zg==.png', '/home/maxim/.keras/datasets/notMNIST_small/H/SVRDIEdvdWR5IFNhbnMgQm9sZC5wZmI=.png', '/home/maxim/.keras/datasets/notMNIST_small/J/QXJpYWxNVFN0ZC5vdGY=.png', '/home/maxim/.keras/datasets/notMNIST_small/D/QmVsdWNpYW4tRGVtaUJvbGQub3Rm.png', '/home/maxim/.keras/datasets/notMNIST_small/G/Rm9ybWFsNDM2IEJULnR0Zg==.png', '/home/maxim/.keras/datasets/notMNIST_small/C/QXVyZWFVbHRyYS1JdGFsaWMub3Rm.png', '/home/maxim/.keras/datasets/notMNIST_small/J/Qm9va21hbiBCVCBJdGFsaWMudHRm.png', '/home/maxim/.keras/datasets/notMNIST_small/F/SVRDIFRpZXBvbG8gQm9vay5wZmI=.png', '/home/maxim/.keras/datasets/notMNIST_small/A/R2VzdGFsdC1IVEYtTGluZWFyLU1lZGl1bS5vdGY=.png']\n"
     ]
    }
   ],
   "source": [
    "all_image_labels = [label_to_index[pathlib.Path(path).parent.name]\n",
    "                    for path in all_image_paths]\n",
    "\n",
    "print(\"First 10 labels indices: \", all_image_labels[:10])\n",
    "print(\"First 10 paths: \", all_image_paths[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14984 images belonging to 10 classes.\n",
      "Found 3740 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "VALIDATION_SET_RATE = 0.2\n",
    "\n",
    "# define image generators for train, validation and test set\n",
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True\n",
    "    validation_split=VALIDATION_SET_RATE\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_HEIGHT = 28\n",
    "IMG_WIDTH = 28\n",
    "IMG_CHANNELS = 3\n",
    "EPOCHS_COUNT = 5\n",
    "\n",
    "\n",
    "\n",
    "train_data_gen = image_generator.flow_from_directory(directory=str(\"/home/maxim/.keras/datasets/notMNIST_small/\"),\n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     shuffle=True,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                     subset='training')\n",
    "STEPS_PER_EPOCH_TRAIN = np.ceil(train_data_gen.samples/BATCH_SIZE)\n",
    "\n",
    "validation_data_gen = image_generator.flow_from_directory(directory=str(\"/home/maxim/.keras/datasets/notMNIST_small/\"),\n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     shuffle=True,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                     subset='validation')\n",
    "\n",
    "STEPS_PER_EPOCH_VALIDATION = np.ceil(validation_data_gen.samples/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 16)        448       \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               1605760   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,624,010\n",
      "Trainable params: 1,624,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 469.0 steps, validate for 117.0 steps\n",
      "Epoch 1/5\n",
      "469/469 [==============================] - 6s 13ms/step - loss: nan - accuracy: 0.1003 - val_loss: nan - val_accuracy: 0.1000\n",
      "Epoch 2/5\n",
      "105/469 [=====>........................] - ETA: 3s - loss: nan - accuracy: 0.1033"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "        layers.Conv2D(16, kernel_size=(3, 3), padding='same', input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax', name='output')\n",
    "    ])\n",
    "model.summary()\n",
    "    \n",
    "# Compile model\n",
    "model.compile(optimizer=SGD(lr=0.0225, decay=0.01, momentum=0.9),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "model.fit_generator(\n",
    "    train_data_gen,\n",
    "    validation_data=validation_data_gen,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH_TRAIN,\n",
    "    validation_steps=STEPS_PER_EPOCH_VALIDATION,\n",
    "    epochs=EPOCHS_COUNT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
