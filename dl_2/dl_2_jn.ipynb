{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/maxim/.keras/datasets/notMNIST_small\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "data_root_orig = tf.keras.utils.get_file(origin='https://commondatastorage.googleapis.com/books1000/notMNIST_small.tar.gz',\n",
    "                                         fname='notMNIST_small', untar=True)\n",
    "data_root = pathlib.Path(data_root_orig)\n",
    "print(data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/maxim/.keras/datasets/notMNIST_small/F\n",
      "/home/maxim/.keras/datasets/notMNIST_small/B\n",
      "/home/maxim/.keras/datasets/notMNIST_small/H\n",
      "/home/maxim/.keras/datasets/notMNIST_small/G\n",
      "/home/maxim/.keras/datasets/notMNIST_small/D\n",
      "/home/maxim/.keras/datasets/notMNIST_small/I\n",
      "/home/maxim/.keras/datasets/notMNIST_small/C\n",
      "/home/maxim/.keras/datasets/notMNIST_small/A\n",
      "/home/maxim/.keras/datasets/notMNIST_small/J\n",
      "/home/maxim/.keras/datasets/notMNIST_small/E\n"
     ]
    }
   ],
   "source": [
    "for letter_dir in data_root.iterdir():\n",
    "  print(letter_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18724"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "all_image_paths = list(data_root.glob('*/*'))\n",
    "all_image_paths = [str(path) for path in all_image_paths]\n",
    "random.shuffle(all_image_paths)\n",
    "\n",
    "image_count = len(all_image_paths)\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABtklEQVR4nG2SsWpUYRCFv/nnrhEhiZAFIa6FCNqYLAgGLZRIirAgaUSwsBBBsBAhTV5ALLSyFc2ihb6BjVYWQRQsUomVSSEWwsoiJLp75z8W9y6iu6cZmI+Z4cyMAZAkTqycWWwdPpiSAUB4twDwoHPr4lyVRDWFAkhx+mEHSrcfnwezbftLwbneV0SpvfsnoVjr5SxJpTbBuS2VCu2eB3NnQ+UIOp2IUI5em0aCwi9HREQM4mmRm09STijd2W4MAaKZKgccKLR+tCwIf/3SS4Dg7VoYIN9l7lsO5axlnDHdUEihj24jA+a1UrGinMjpVRTlaAkxKkwLlsD5MN4T6Ckra3CKNM7SNAYMemgC1H9z/oF9BBSz2AS4gzCmWhPhNoKwBZsE35BALCuPUlbUSsx8yaGs/jEb92JsPAgn/NF6dZSUz139nYA89Q6b/qRSisEqDQMKu6ZaL5L9vLnvgTWeXxgqubsshtWx98C5sq+hsgb3WgBz7xX1mxh4rHbnCZzvW1s7M3fb1feFdwGc+WdDKf+qRkUVSm1SUZYef5WkXA5rVrcFkgXNS2cXjx851BiZDO/+Af1D+fFZ9ebdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/maxim/.keras/datasets/notMNIST_small/C/RHVzdFBpZWNlLm90Zg==.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA3ElEQVR4nKWROw7CQAxEx94lfJSC+1AizoO4CXfhEBScgR5aQApssjZF2IQ1hAZXlp5mbI+x0loHquYxBqvxk9SKGEZ3X6Se2SpLX4AAQPi4n+VauiTbyLtNEYw02RICnLdwnGCFphmEAUQ5U9/dWUH1cya1SsF0lG97p+1a2gNvVe4a58vetixzz+hcD2MegYJCH59zuVKYO2U8nPz7tsrhjJ1GVRW9LmCkgB+1p0AJzoQQe9sKjf0op2fLw5oCXPyCna195juUB2zuCep35esr/8ysaWgmEEGW4QkV/mc2i+YX6AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/maxim/.keras/datasets/notMNIST_small/F/SHVtYW5zdDUzMSBCVCBCb2xkLnR0Zg==.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABP0lEQVR4nG2RoUueYRTFz33eVwfqhIEg02ASFASD2SayIGIUhaWZLDaDcShmsQzTDCaTRfYHGDY0CENmUtFgGXyg4vC7z/2tWD7f59Yf595zzzG9TpVnt19MabwXw+6v6uj+rY5JGn8iyMyp6iQyq7WFkzntUTKzTqr+azLOumq9nVrLOEFrWNaA0g8cZ0+pQZKm2hAw07Aj1dqhTeZnYWnS4B2Bs1IQVvpCJnM7VDhpOsFxdgt/VJqGAKaKXr/hOMdq+jF9/EuQ+VxMZw0nuOkrCd/9ItPma/HiDEHwOFmAlQ5wnKNCAEmjLYLMfDGddZzM+fuSna4LMs5GMZ0FIoKHkUIhpkMc53uxrLF/EPCp2PImTubsrdDMkj5cknFWVTfWVlokk7kbVuqoxPYnXpKPDmBY608V3TdLz8Yr/A/Ax7i6gH1aPQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/maxim/.keras/datasets/notMNIST_small/I/MTIgV2FsYmF1bSBJdGFsaWMgMTMyNjMudHRm.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABWUlEQVR4nHXQMUubURTG8f+5900prVhp4yARgmQJKgkkWERw6Ori5FfoF/AT2FFwd3VyEVzr0KFLsWILhQa1Uy1qFVItcTC8ed/7ODTBIjdn/XEOz3MgNo4tpdpyURRNxJcoOlUmeJK2omjUXwbOvg/BGXqcXcXQMmoYh8QDjTZw7A8pUpWkanTTmCPn6HIIzpPR+usiaIEZoIWP4uQUBb4SIlc9i8rVKWHRKtPk/LxAERTziM+yWNrAHHCIj6BRLlHgGEXQ0RgLdvojikadHqe/XSABA/1nGQ2Mbxjw+EeO8q0yLfVvuhdl/4AF1tTTyRgGvNk7+NOepc9WoH6jVG9JAFaUZ9rA+SRJvHNUT9TVNgaA/6RurrWnGBjF1bZS7Y78Q6P5vhjkf3047jx/VXs9Luuuvwv9/I7KTqqgwZxvTuNsUNlJteWFqeIzf3d9fvRxr20u9HvfA8sKiJ6C+P20AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/maxim/.keras/datasets/notMNIST_small/J/QXZlbmlyIDQ1IEJvb2sgT2JsaXF1ZS5wZmI=.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABnklEQVR4nGWSMWtUURBGv3vvE0QF4260UFYUxAQRwSJFClGsJEKwsElhaSX4HywEEbHQRuyEYIIoG8FaGxtBQQQhiIWGNBEMxEWNeXPnWLy37NvdaQ/nm7kzN6hRaa/vmThw8GhnsrXdfUFooKD22/X1XxkA51Wr6YWgLiXkbGZmvNk3lKo5ytI9Z4AdbmnI1SOqVMD5WDQhuvnl2mH1Ns8WEuG3hisqTbQ1D2DcH4GhCIrqUuJwRaMVkk6VOJnPu+MoRLpe5CC0uD1mRp34geP0psaYku5gYDxXGmupk1s4OBc11jLqaSWuKIQRlnS58srzY2LU5FcyGM8qFgd2SFrGwPk3oyQpKPT9mHQPA4yH9aizx1WkGGMqpLsYkPl+qEptr306oyApqPOSEiCzUIs3yH+Xrk4f6Vx4sFkds2RR9RxP2MlgP3vgVp3qfasPV8iYAbn0im1M959YrAklIcUoSVZszK+mXM8/l7P3vw1mrJ5uLvwxlrO7u5k7S62hY+y6/Yfaza8vDVYiKYTgUwvnju3X1rd33Q+e8AH8D4YAGU2NYZMGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/maxim/.keras/datasets/notMNIST_small/J/SG91c2VNb3ZlbWVudHMtU2lnbi5vdGY=.png\n"
     ]
    }
   ],
   "source": [
    "all_image_paths[:10]\n",
    "\n",
    "import IPython.display as display\n",
    "\n",
    "for n in range(5):\n",
    "  image_path = random.choice(all_image_paths)\n",
    "  display.display(display.Image(image_path))\n",
    "  print(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0,\n",
       " 'B': 1,\n",
       " 'C': 2,\n",
       " 'D': 3,\n",
       " 'E': 4,\n",
       " 'F': 5,\n",
       " 'G': 6,\n",
       " 'H': 7,\n",
       " 'I': 8,\n",
       " 'J': 9}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_index = dict((name, index) for index, name in enumerate(label_names))\n",
    "label_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 labels indices:  [1, 0, 7, 0, 3, 1, 0, 9, 8, 6]\n",
      "First 10 paths:  ['/home/maxim/.keras/datasets/notMNIST_small/B/RnV0dXJhQlQtRXh0cmFCbGFja0NvbmRJdGFsaWMub3Rm.png', '/home/maxim/.keras/datasets/notMNIST_small/A/Q2xhcmVuZG9uIEh2IEJUIEhlYXZ5LnR0Zg==.png', '/home/maxim/.keras/datasets/notMNIST_small/H/SGVhZGxpbmUgV2lkZSBCb2xkSXRhbGljLnR0Zg==.png', '/home/maxim/.keras/datasets/notMNIST_small/A/R290aGljIDcyMCBJdGFsaWMgQlQudHRm.png', '/home/maxim/.keras/datasets/notMNIST_small/D/SHViYnViIFNTaSBCb2xkLnR0Zg==.png', '/home/maxim/.keras/datasets/notMNIST_small/B/R2FydGhHcmFwaGljLUNvbmRlbnNlZC5vdGY=.png', '/home/maxim/.keras/datasets/notMNIST_small/A/R291ZHlDYXRhbG9ndWVNVFN0ZC1JdGFsaWMub3Rm.png', '/home/maxim/.keras/datasets/notMNIST_small/J/Q3VzaGluZ0l0Y1RFRUhlYS50dGY=.png', '/home/maxim/.keras/datasets/notMNIST_small/I/RXJhc0JRLUxpZ2h0Lm90Zg==.png', '/home/maxim/.keras/datasets/notMNIST_small/G/QXVndXN0LUxpZ2h0Lm90Zg==.png']\n"
     ]
    }
   ],
   "source": [
    "all_image_labels = [label_to_index[pathlib.Path(path).parent.name]\n",
    "                    for path in all_image_paths]\n",
    "\n",
    "print(\"First 10 labels indices: \", all_image_labels[:10])\n",
    "print(\"First 10 paths: \", all_image_paths[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Tensor: shape=(), dtype=string, numpy=b\"\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x1c\\x00\\...\n",
      "(28, 28, 1)\n",
      "<dtype: 'uint8'>\n"
     ]
    }
   ],
   "source": [
    "img_path = all_image_paths[0]\n",
    "img_path\n",
    "img_raw = tf.io.read_file(img_path)\n",
    "print(repr(img_raw)[:100]+\"...\")\n",
    "\n",
    "img_tensor = tf.image.decode_image(img_raw)\n",
    "\n",
    "print(img_tensor.shape)\n",
    "print(img_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "  image = tf.image.decode_jpeg(image, channels=1)\n",
    "  image = tf.image.resize(image, [28, 28])\n",
    "  return image\n",
    "\n",
    "def load_and_preprocess_image(path):\n",
    "  image = tf.io.read_file(path)\n",
    "  return preprocess_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (), types: tf.string>\n"
     ]
    }
   ],
   "source": [
    "path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n",
    "print(path_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n",
      "A\n",
      "H\n",
      "A\n",
      "D\n",
      "B\n",
      "A\n",
      "J\n",
      "I\n",
      "G\n",
      "<TensorSliceDataset shapes: (), types: tf.int64>\n",
      "<ZipDataset shapes: ((28, 28, 1), ()), types: (tf.float32, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(all_image_labels, tf.int64))\n",
    "\n",
    "for label in label_ds.take(10):\n",
    "  print(label_names[label.numpy()])\n",
    "\n",
    "print(label_ds)\n",
    "\n",
    "image_label_ds = tf.data.Dataset.zip((image_ds, label_ds))\n",
    "print(image_label_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices((all_image_paths, all_image_labels))\n",
    "\n",
    "# Кортежи распаковываются в позиционные аргументы отображаемой функции\n",
    "def load_and_preprocess_from_path_label(path, label):\n",
    "  return load_and_preprocess_image(path), label\n",
    "\n",
    "image_label_ds = ds.map(load_and_preprocess_from_path_label)\n",
    "image_label_ds\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Установка размера буфера перемешивания, равного набору данных, гарантирует\n",
    "# полное перемешивание данных.\n",
    "# ds = image_label_ds.shuffle(buffer_size=image_count)\n",
    "# ds = ds.repeat()\n",
    "# ds = ds.batch(BATCH_SIZE)\n",
    "# # `prefetch` позволяет датасету извлекать пакеты в фоновом режиме, во время обучения модели.\n",
    "# ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "ds = image_label_ds.apply(\n",
    "  tf.data.experimental.shuffle_and_repeat(buffer_size=image_count))\n",
    "ds = ds.batch(BATCH_SIZE)\n",
    "ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 10 steps\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 2s 235ms/step - loss: 119.0451 - accuracy: 0.8781\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 103.6883 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 103.0410 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 99.5868 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 104.4078 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 97.2842 - accuracy: 0.9969\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 110.0924 - accuracy: 0.9969\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 108.5813 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 102.5408 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 106.4946 - accuracy: 0.9937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f751c865550>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.Sequential([\n",
    "            keras.layers.Input(shape=(28, 28, 1)),\n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            keras.layers.Dense(64, activation='relu'),\n",
    "            keras.layers.Dropout(0.4),\n",
    "            keras.layers.Dense(64, activation='relu'),\n",
    "            keras.layers.Dropout(0.1),\n",
    "            keras.layers.Dense(10, activation='sigmoid')\n",
    "        ])\n",
    "model.compile(optimizer='sgd',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "model.fit(ds, steps_per_epoch=10, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
